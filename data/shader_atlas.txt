//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
//forward
skybox basic.vs skybox.fs
reflection basic.vs reflection.fs
multi_pass basic.vs multi_pass.fs
single_pass basic.vs single_pass.fs 
//deferred
g_buffers basic.vs g_buffers.fs
deferred_multi_pass quad.vs deferred_multi_pass.fs
deferred_geometry basic.vs deferred_multi_pass.fs
deferred_ambient quad.vs deferred_ambient.fs

//FX
ssao quad.vs ssao.fs
tonemapper quad.vs tonemapper.fs
add_reflections quad.vs add_reflections.fs
AAFX quad.vs AAFX.fs
bloom quad.vs bloom.fs
DOF quad.vs dof.fs

//irradiance
probe basic.vs probe.fs
irr quad.vs irr.fs

//Volume Rendering
volume_ambient quad.vs volume_fog.fs
volume_geo basic.vs volume_fog.fs

//blur
gaussian_blur quad.vs gaussian_blur.fs

//decals
decal basic.vs decal.fs

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

uniform float u_time;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}
/**************************************************************************************************************/
\SHs
const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}

\irradiance
#include "SHs"
uniform vec3 u_irr_start;
uniform vec3 u_irr_end;
uniform vec3 u_irr_delta;
uniform vec3 u_irr_dimensions;
uniform float u_irr_size;
uniform float u_irr_normal_dist;
uniform int u_irr_probes_num;
uniform sampler2D u_probes_texture;

uniform bool u_irr_active;
vec3 computeIrr(vec3 indexes, vec3 N){

	//compute in which row is the probe stored
	float row = indexes.x + indexes.y * u_irr_dimensions.x + indexes.z * u_irr_dimensions.x * u_irr_dimensions.y;

	//find the UV.y coord of that row in the probes texture
	float row_uv = (row + 1.0) / (u_irr_probes_num + 1.0);

	SH9Color sh;
	//fill the coefficients
	const float d_uvx = 1.0 / 9.0;
	for(int i = 0; i < 9; ++i)
	{
		vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		sh.c[i] = texture( u_probes_texture, coeffs_uv).xyz;
	}

	//now we can use the coefficients to compute the irradiance
	return ComputeSHIrradiance( N, sh );
}

vec3 interpolateSHs(vec3 local_indices, vec3 factors, vec3 N){
	//fetch the SHs for all 8 probes
	//compute irradiance for every corner
	vec3 irrLBF = computeIrr( local_indices, N );

	vec3 indicesRBF = local_indices + vec3(1,0,0);
	vec3 irrRBF = computeIrr( indicesRBF, N);

	vec3 indicesLTF = local_indices + vec3(0,0,1);
	vec3 irrLTF = computeIrr( indicesLTF, N );

	vec3 indicesRTF = local_indices + vec3(1,0,1);
	vec3 irrRTF = computeIrr( indicesRTF, N );

	vec3 indicesLBN = local_indices + vec3(0,1,0);
	vec3 irrLBN = computeIrr( indicesLBN, N );

	vec3 indicesRBN = local_indices + vec3(1,1,0);
	vec3 irrRBN = computeIrr( indicesRBN, N );

	vec3 indicesLTN = local_indices + vec3(0,1,1);
	vec3 irrLTN = computeIrr( indicesLTN, N );

	vec3 indicesRTN = local_indices + vec3(1,1,1);
	vec3 irrRTN = computeIrr( indicesRTN, N  );

	//interpolate
	vec3 irrBF = mix( irrLBF, irrRBF, factors.x );
	vec3 irrTF = mix( irrLTF, irrRTF, factors.x );
	vec3 irrBN = mix( irrLBN, irrRBN, factors.x );
	vec3 irrTN = mix( irrLTN, irrRTN, factors.x );

	vec3 irrT = mix(irrBF, irrTF, factors.z );
	vec3 irrB = mix( irrBN, irrTN, factors.z );

	vec3 irr = mix( irrT, irrB, factors.y );

	return irr;
}

bool inside(vec3 range, vec3 position){
	int factor = 0;
	if (position.x < factor || position.y < -20 || position.z < factor || position.x > range.x || position.y > range.y || position.z > range.z){
		return false;
	}
	return true;
}

vec3 Irradiance(vec3 wp, vec3 N){
	//computing nearest probe index based on world position
	vec3 irr_range = u_irr_end - u_irr_start;

	vec3 irr_local_pos = wp - u_irr_start + N * u_irr_normal_dist;
	
	if(inside(irr_range-1, irr_local_pos) == false){
		irr_local_pos = irr_range -1;
	}
		
	//irr_local_pos = clamp( irr_local_pos, vec3(0.0), irr_range -1 );

	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;

	//floor instead of round
	vec3 local_indices = floor( irr_norm_pos );

	//now we have the interpolation factors
	vec3 factors = irr_norm_pos - local_indices;

	vec3 irradiance = interpolateSHs(local_indices, factors, N);

	return irradiance;
}



\light_attenuation
if(u_light_type == 2){ //directional
		L = normalize(-u_light_direction);
}else{
	L = normalize(u_light_pos - world_position);
	//compute distance
	float light_distance = length(u_light_pos - world_position);

	//compute a linear attenuation factor
	att_factor = u_light_maxdist - light_distance;

	//normalize factor


	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );

	if(u_light_type == 1){ //spot
			
		vec3 D = normalize(u_light_direction);

		float spotCos = dot(D,-L);

		if(spotCos >= u_cosCutoff){
			spotFactor = pow(spotCos, u_spot_exp);
		}else{
			spotFactor = 0.0;
		}
	}
}

\shadows
//shadows
uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

float computeShadow(vec3 world_position){
	vec4 proj_pos = u_shadow_viewproj * vec4(world_position,1.0);

	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

	real_depth = real_depth * 0.5 + 0.5;

	float shadow_depth = texture( u_shadowmap, shadow_uv).x;
	float shadow_factor = 1.0;

	if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
			return 1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return 1.0;

	if( shadow_depth < real_depth )
		shadow_factor = 0.0;
	
	return shadow_factor;
}

\color_correction
#define GAMMA 2.2
#define INV_GAMMA 0.45

// degamma
vec3 gamma_to_linear(vec3 color)
{
	return pow(color, vec3(INV_GAMMA));
}

// gamma
vec3 linear_to_gamma(vec3 color)
{
	return pow(color, vec3(GAMMA));
}

\light_uniforms

uniform vec3 u_light_pos;
uniform vec3 u_light_ambient;
uniform vec3 u_light_color;
uniform vec3 u_light_direction;
uniform int u_light_type;
uniform float u_light_maxdist;
uniform float u_cosCutoff;
uniform float u_light_intensity;
uniform float u_spot_exp;
uniform int u_iteration;

struct sLVectors{
	vec3 N;
	vec3 L;
	vec3 V;
	vec3 R;
	vec3 H;
};

struct sDots{
	float NdotL;
	float NdotV;
	float NdotH;
	float LdotH;
};


sLVectors set_vectors(vec2 uv, vec3 N, vec3 cam_pos, vec3 world_position){
	sLVectors vectors;

	vectors.N = N;	
	vectors.V = normalize(cam_pos - world_position);
	vectors.R = normalize(reflect(-vectors.L,vectors.N));
	vectors.H = normalize(vectors.V + vectors.L);

	return vectors;
}

sDots computeDots(sLVectors vectors){
	sDots dots;
	float low_clamp_factor = 0.001;
	
	/*dots.NdotL = max(low_clamp_factor,dot(vectors.N,vectors.L));
	dots.NdotV = max(low_clamp_factor,dot(vectors.N,vectors.V));
	dots.NdotH = max(low_clamp_factor,dot(vectors.N,vectors.H));
	dots.LdotH = max(low_clamp_factor,dot(vectors.L, vectors.H));*/

	dots.NdotL = clamp(dot(vectors.N,vectors.L),0.001,0.99);
	dots.NdotV = clamp(dot(vectors.N,vectors.V),0.001,0.99);
	dots.NdotH = clamp(dot(vectors.N,vectors.H),0.001,0.99);
	dots.LdotH = clamp(dot(vectors.L, vectors.H),0.001,0.99);

	return dots;
} 


//PBR
#define RECIPROCAL_PI 0.3183098861837697
#define PI 3.14159265359


// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, const in float linearRoughness ){
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Fresnel term with scalar optimization(f90=1)
float F_SchlickF( const in float VoH, const in float f0){
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (1.0 - f0) * f;
}


// Fresnel term with colorized fresnel
vec3 F_SchlickV( const in float VoH, const in vec3 f0){
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}


vec3 specularBRDF( float roughness, vec3 f0, sDots dots){
	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX( dots.NdotH, a );

	// Fresnel Function
	vec3 F = F_SchlickV( dots.LdotH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( dots.NdotV, dots.NdotL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * dots.NdotL * dots.NdotV + 1e-6);

	return spec;
}

#include "shadows"
#include "color_correction"

vec3 computePBR(sLVectors vectors, vec3 world_position, float roughness, vec3 F0, vec3 Cdiffuse){
	
	vec3 L; 
	float spotFactor = 1.0;
	float att_factor = 1.0;

	#include "light_attenuation"

	vectors.L = L;

	sDots dots = computeDots(vectors);

	vec3 specular = specularBRDF(roughness, F0, dots);

	vec3 diffuse = Cdiffuse*dots.NdotL;

	vec3 direct = diffuse + specular*dots.NdotL;

	vec3 light_color = gamma_to_linear(u_light_color);

	vec3 light_param = light_color*u_light_intensity*att_factor*spotFactor;

	vec3 light = direct*light_param;

	if(u_light_type != 0 && light != vec3(0.0)){
		light *= computeShadow(world_position);
	}

	return light;
}


vec3 computePhong(vec3 N, vec3 world_position){

	vec3 L; 
	vec3 light = vec3(0.0);
	float spotFactor = 1.0;
	float att_factor = 1.0;
	vec3 light_color = gamma_to_linear(u_light_color);

	#include "light_attenuation"

	float NdotL = dot(N,L);
	NdotL = clamp( NdotL, 0.0, 1.0 );	
	
	light += NdotL*light_color*u_light_intensity*att_factor*spotFactor;

	if(u_light_type != 0 && light != vec3(0.0)){
		light *= computeShadow(world_position);
	}

	return light;

}

\material 

//#include "color_correction"

uniform sampler2D u_albedo;
uniform sampler2D u_omr;
uniform sampler2D u_emissive;
uniform bool u_has_omr;

struct sMaterial
{
	vec4 albedo; //albedo color RGB
	vec3 F0; //Fresnel value RGB
	vec3 Cdiffuse; //diffuse value
	float metalness; //metalness
	float roughness; //roughness
	float ao; //baked ambient occlusion
	vec3 emission; //emissive 
};

//init all the material properties
sMaterial init_material(vec2 uv){
	sMaterial material;

	material.albedo = texture2D( u_albedo, uv ); 
	//degamma
	material.albedo.xyz = gamma_to_linear(material.albedo.xyz);

	if(u_has_omr){
		material.roughness = max(0.01, texture2D( u_omr, uv ).y); 
		material.metalness = min(texture2D( u_omr, uv ).z,0.99);
	}else{
		material.roughness = 0.5; 
		material.metalness = 0.0;
	}

	material.F0 = mix( vec3(0.5), material.albedo.xyz, material.metalness );
	material.Cdiffuse = material.albedo.xyz*(vec3(1.0) - vec3(material.metalness));

	material.ao = texture2D(u_omr, uv).x;
	material.emission = gamma_to_linear(texture2D(u_emissive,uv).xyz);
	return material;
}


\realistic_normals
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}

// assume N, the interpolated vertex normal and 
// WP the world position
//vec3 normal_pixel = texture2D( normalmap, uv ).xyz; 
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
	normal_pixel = normal_pixel * 255./127. - 128./127.;
	mat3 TBN = cotangent_frame(N, WP, uv);
	return normalize(TBN * normal_pixel);
}

\multi_pass.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;

uniform sampler2D u_normal_map;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform mat4 u_model;
uniform vec3 u_camera_position;

#include "light_uniforms"
#include "material"

#include "realistic_normals"

//uniform float u_emissive_factor;
uniform bool u_has_emissive;
uniform bool u_has_normal;

uniform bool u_has_shadows;

uniform int u_ilum_mode;

uniform int u_max_iter;

uniform samplerCube u_environment_texture;

out vec4 FragColor;

void main()
{
	vec4 color = u_color;

	sMaterial material = init_material(v_uv);

	color *= material.albedo;

	vec3 total_light = vec3(0.0);
	if(u_iteration == 0){
		total_light += gamma_to_linear(u_light_ambient);
		if(u_has_omr) {
			total_light *= material.ao;
		}
	}
	
	//light equation vectors
	vec3 N = normalize(v_normal);
	vec3 V = normalize(v_world_position-u_camera_position); 
	
	if(u_has_normal){
		vec3 np = texture( u_normal_map, v_uv ).xyz;
		N = perturbNormal(N, V, v_uv, np);
	}

	if(u_ilum_mode == 0){
		total_light += computePhong(N,v_world_position);
	}else if(u_ilum_mode == 1){
		sLVectors vectors = set_vectors(v_uv, N, u_camera_position, v_world_position);
		vec3 PBR = computePBR(vectors, v_world_position, material.roughness, material.F0, material.Cdiffuse);
		total_light += PBR;
	}
	
	color.xyz *= total_light; 

	if(color.a < u_alpha_cutoff)
		discard;

	if(u_iteration == 0 && u_has_emissive){
		color.xyz += material.emission;
	}
	vec3 R = reflect(V,N);
	if(u_iteration == u_max_iter){

		color.xyz = material.albedo.xyz*textureLod(u_environment_texture, R, material.roughness*5.0).xyz*0.6;
		color.w = material.metalness;
	}

	FragColor = color;	
}

\single_pass.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;

uniform sampler2D u_albedo;
uniform sampler2D u_normal_map;
uniform sampler2D u_emissive;
uniform sampler2D u_omr;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform mat4 u_model;
uniform vec3 u_camera_position;

const int MAX_LIGHTS = 6;
uniform vec3 u_light_pos[MAX_LIGHTS];
uniform vec3 u_light_color[MAX_LIGHTS];
uniform vec3 u_light_ambient;
uniform vec3 u_light_direction[MAX_LIGHTS];
uniform int u_light_type[MAX_LIGHTS];
uniform float u_light_maxdist[MAX_LIGHTS];
uniform float u_cosCutoff[MAX_LIGHTS];
uniform float u_light_intensity[MAX_LIGHTS];
uniform float u_spot_exp[MAX_LIGHTS];

uniform int u_num_lights;

uniform bool u_has_emissive;

uniform bool u_has_normal;
uniform bool u_has_ao;

out vec4 FragColor;

#include "realistic_normals"

void main()
{
	vec3 light = vec3(0.0);
	light += u_light_ambient;
	if(u_has_ao){
		light *= vec3(texture( u_omr, v_uv ).x);
	}

	vec4 color = u_color;
	color *= texture( u_albedo, v_uv );

	//light equation vectors
	vec3 N = normalize(v_normal);
	vec3 V = normalize(u_camera_position - v_world_position);
	vec3 L = vec3(0.0);
	float att_factor = 1.0; 
	float spotFactor = 1.0;
	vec3 light_color;

	if(u_has_normal){
		vec3 np = texture( u_normal_map, v_uv ).xyz;
		N = perturbNormal(N, V, v_uv, np);
	}

	for(int i = 0; i < MAX_LIGHTS; i++){
		if(i < u_num_lights){
			att_factor = 1.0; 
			spotFactor = 1.0;
			light_color = u_light_color[i];

			if(u_light_type[i] == 2){
				L = normalize(-u_light_direction[i]);
			}else{
				L = normalize(u_light_pos[i] - v_world_position);

				float light_distance = length(u_light_pos[i] - v_world_position);

				//compute a linear attenuation factor
				att_factor = u_light_maxdist[i] - light_distance;

				//normalize factor
				att_factor /= u_light_maxdist[i];

				//ignore negative values
				att_factor = max( att_factor, 0.0 );

				if(u_light_type[i] == 1){ //spot
			
					vec3 D = normalize(u_light_direction[i]);

					float spotCos = dot(D,-L);

					if(spotCos >= u_cosCutoff[i]){
						spotFactor = pow(spotCos, u_spot_exp[i]);
					}else{
						light_color = vec3(0.0);
					}
				}
			}
			
			float NdotL = max(dot(N,L),0.0);
			light += NdotL*light_color*u_light_intensity[i]*att_factor*spotFactor;
		}
	}

	color.xyz *= light; 

	if(u_has_emissive){

		color.xyz += texture( u_emissive, v_uv ).xyz;//*u_emissive_factor;
	}

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;	
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_coord;
out vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4( a_vertex, 1.0 );
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_albedo;
uniform float u_time;
uniform float u_alpha_cutoff;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_albedo, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}


\skybox.fs

#version 330 core

in vec3 v_world_position;

uniform vec4 u_color;
uniform samplerCube u_texture;
uniform vec3 u_camera_position;
#include "color_correction"
uniform bool u_is_forward;
out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_position;
	vec3 skybox_color = texture( u_texture, V , 0.0).xyz;

	if(u_is_forward)
		skybox_color = gamma_to_linear(skybox_color);

	vec4 color = vec4(skybox_color,1.0);

	FragColor = color;
}

\reflection.fs

#version 330 core

in vec3 v_normal;
in vec3 v_world_position;

uniform vec4 u_color;
uniform samplerCube u_texture;
uniform vec3 u_camera_position;
#include "color_correction"

out vec4 FragColor;

void main()
{
	vec3 N = normalize(v_normal);
	vec3 V = v_world_position - u_camera_position;
	vec3 R = reflect(V,N);
	vec3 skybox_color = texture( u_texture, R ).xyz;
	vec4 color = vec4(skybox_color,1.0);

	FragColor = color;
}


\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_albedo;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_albedo, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}


\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}


\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}


/***************************************************************************************************************************/
//deferred

\g_buffers.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform float u_alpha_cutoff;

uniform sampler2D u_albedo;
uniform sampler2D u_omr;
uniform sampler2D u_normal_map;
uniform sampler2D u_emissive;

uniform bool u_has_normal;

uniform vec3 u_camera_position;

#include "realistic_normals"

uniform bool u_blending_mat;

float dither4x4(vec2 position, float brightness)
{
  int x = int(mod(position.x, 4.0));
  int y = int(mod(position.y, 4.0));
  int index = x + y * 4;
  float limit = 0.0;

  if (x < 8) {
    if (index == 0) limit = 0.0625;
    if (index == 1) limit = 0.5625;
    if (index == 2) limit = 0.1875;
    if (index == 3) limit = 0.6875;
    if (index == 4) limit = 0.8125;
    if (index == 5) limit = 0.3125;
    if (index == 6) limit = 0.9375;
    if (index == 7) limit = 0.4375;
    if (index == 8) limit = 0.25;
    if (index == 9) limit = 0.75;
    if (index == 10) limit = 0.125;
    if (index == 11) limit = 0.625;
    if (index == 12) limit = 1.0;
    if (index == 13) limit = 0.5;
    if (index == 14) limit = 0.875;
    if (index == 15) limit = 0.375;
  }

  return brightness < limit ? 0.0 : 1.0;
}

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 OMR; //occlussion_metalness_roughness
layout(location = 3) out vec4 EmissiveColor; //emissive


void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_albedo, v_uv );

	vec3 N = normalize(v_normal);

	if(u_has_normal){
		vec3 V = normalize(v_world_position-u_camera_position);
		vec3 np = texture( u_normal_map, v_uv ).xyz;
		N = perturbNormal(N, V, v_uv, np);
	}

	if(color.a < u_alpha_cutoff)
		discard;

	NormalColor = vec4(N*0.5 + vec3(0.5),1.0);
	OMR = texture( u_omr, v_uv );
	EmissiveColor = texture( u_emissive, v_uv );
	FragColor = color;

}

\deferred_multi_pass.fs

#version 330 core

in vec2 v_uv;

#include "light_uniforms"
#include "material"

uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform int u_ilum_mode;

uniform sampler2D u_ssao;
uniform bool u_apply_ssao;

uniform bool u_apply_irradiance;
uniform sampler2D u_irradiance;
uniform float u_far_plane;
uniform float u_bloom_thr;

layout (location = 0) out vec4 FragColor;
layout (location = 1) out vec4 BrightColor;

void main()
{
	//extract uvs from pixel screenpos. From  [-1 1]to [0 1]
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	sMaterial material = init_material(uv);

	vec4 color = material.albedo;

	//From [0 1]to [-1 1], and inverse to get world position
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_pos = proj_worldpos.xyz / proj_worldpos.w;

	//revert the normalisation during pre-pass
	vec3 N = texture( u_normal_texture, uv ).xyz*2.0-vec3(1.0);
	N = normalize(N);
	
	vec3 total_light = vec3(0.0);

	if(u_iteration == 0){
		if(depth >= 1.0)
		{
			FragColor = material.albedo;
			return;
		}
		total_light += gamma_to_linear(u_light_ambient);
		if(u_apply_ssao){
			material.ao = texture( u_ssao, uv ).x;
		}
		total_light *= material.ao;
	}else{
		if(depth >= 1.0)
		{
			FragColor = vec4(vec3(0.0),1.0);
			return;
		}
		if(u_ilum_mode == 0){

			total_light += computePhong(N,world_pos);

		}else if(u_ilum_mode == 1){
			sLVectors vectors = set_vectors(uv, N, u_camera_position, world_pos);
			vec3 PBR = computePBR(vectors, world_pos, material.roughness, material.F0, material.Cdiffuse);
			total_light += PBR;
		}
	}
	color.xyz *= total_light;

	if(u_iteration == 0){
		if(u_apply_irradiance){
			color.xyz += texture(u_irradiance, uv).xyz*0.5;

		}
		color.xyz += material.emission;
	}

	//fog effect
	//float dist2 = length(world_pos - u_camera_position);
	//dist2 = clamp(dist2/u_far_plane, 0.0, 1.0);
	//color = mix(color,vec4(0.0),dist2);

	FragColor = color;
	//float brightness = dot(FragColor.xyz, vec3(0.2126, 0.7152, 0.0722));

	float brightness = max(color.x, max(color.y, color.z));
	float contribution = max(0, brightness - u_bloom_thr);
	contribution /= max(brightness, 0.00001);
	BrightColor = color * contribution;

    /*if(brightness > u_bloom_thr)
        BrightColor = vec4(FragColor.xyz, 1.0);
    else
        BrightColor = vec4(vec3(0.0), 1.0);*/
	
}

\ssao.fs

#version 330 core

#define MAX_POINTS 64

in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;

uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform int u_ilum_mode;

uniform float u_bias_slider;
uniform float u_max_distance;

uniform float u_radius;

uniform vec3 u_points[MAX_POINTS];

#include "realistic_normals"

out vec4 FragColor;

void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv + u_iRes * 0.5;

	//read depth from depth buffer
	float depth = texture( u_depth_texture, uv ).x;

	//revert the normalisation during pre-pass
	vec3 N = texture( u_normal_texture, uv ).xyz*2.0-vec3(1.0);
	N = normalize(N);

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;


	const int samples = MAX_POINTS;
	int num = samples; //num samples that passed the are outside

	//to create the matrix33 to convert from tangent to world
	mat3 rotmat = cotangent_frame( N, worldpos, v_uv ); //Preguntar la alternativa a estas uv
	//for every sample around the point

	for( int i = 0; i < samples; ++i )
	{
		
		vec3 random_point =  (rotmat * u_points[i])* u_radius;

		//vec3 random_point = u_points[i] *u_radius;

		//compute is world position using the random
		vec3 p = worldpos + random_point;

		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p,1.0);

		proj.xy /= proj.w; //convert to clipspace from homogeneous
		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - u_bias_slider) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;

		//compare true depth with its depth
		if( pdepth < proj.z && (abs(pdepth - proj.z) < u_max_distance*0.01)) //if true depth smaller, is inside
			num--; //remove this point from the list of visible

		//Mirar si la distancia (en lineal) entre el punt i el test es gran, no tenir en compte l'oclusi�
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);
	vec4 color = vec4(vec3(ao), 1.0);
	
	FragColor = color;
}


\tonemapper.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform float u_average_lum;
uniform float u_lumwhite2;
uniform float u_scale;
uniform bool u_apply;

#include "color_correction"

out vec4 FragColor;

void main() {
	vec4 color = texture2D(u_texture, v_uv);
	vec3 rgb = color.xyz;
	if(u_apply){
		float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
		float L = (u_scale / u_average_lum) * lum;
		float Ld = (L * (1.0 + L / u_lumwhite2)) / (1.0 + L);

		rgb = (rgb / lum) * Ld;
		rgb = max(rgb,vec3(0.001));
	}
	rgb = linear_to_gamma(rgb);
	gl_FragColor = vec4( rgb, color.a );
}

\deferred_ambient.fs

#version 330 core

in vec2 v_uv;

uniform vec3 u_light_ambient;
#include "color_correction"
#include "material"

uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform sampler2D u_ssao;
uniform bool u_apply_ssao;

uniform bool u_apply_irradiance;
#include "irradiance"


out vec4 FragColor;

void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	//read depth from depth buffer
	float depth = texture( u_depth_texture, uv ).x;

	//revert the normalisation during pre-pass
	vec3 N = texture( u_normal_texture, uv ).xyz*2.0-vec3(1.0);
	N = normalize(N);

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	sMaterial material = init_material(uv);

	if(u_apply_ssao)
		material.ao = texture( u_ssao, uv ).x;

	vec4 color = material.albedo;
	
	vec3 total_light = vec3(0.0);

	total_light += gamma_to_linear(u_light_ambient);	
	total_light *= material.ao;

	color.xyz *= total_light;

	if(u_irr_active && u_apply_irradiance){
		vec3 irradiance = Irradiance(worldpos, N);
		color.xyz += linear_to_gamma(irradiance);
	}

	color.xyz += material.emission;

	//color.xyz = linear_to_gamma(color.xyz); //we will apply this in the tonemapper
	FragColor = color;
}

\probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;


uniform vec3  u_coeffs[9];

out vec4 FragColor;

#include "SHs"

void main()
{
	vec3 N = normalize(v_normal);
	
	//Donada una normal, i sabent els coefficients, donam color
	SH9Color sh;
	sh.c[0] = u_coeffs[0];
	sh.c[1] = u_coeffs[1];
	sh.c[2] = u_coeffs[2];
	sh.c[3] = u_coeffs[3];
	sh.c[4] = u_coeffs[4];
	sh.c[5] = u_coeffs[5];
	sh.c[6] = u_coeffs[6];
	sh.c[7] = u_coeffs[7];
	sh.c[8] = u_coeffs[8];
	

	vec4 color = vec4 (ComputeSHIrradiance(N,sh),1.0);
	
	
	FragColor = color;
}


\irr.fs
#version 330 core

#define MAX_POINTS 64

in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

#include "irradiance"

out vec4 FragColor;

void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv + u_iRes * 0.5;

	//read depth from depth buffer
	float depth = texture( u_depth_texture, uv ).x;

	//revert the normalisation during pre-pass
	vec3 N = texture( u_normal_texture, uv ).xyz*2.0-vec3(1.0);
	N = normalize(N);

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(0.0);
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	vec4 color = vec4(0.0);

	if(u_irr_active){
		vec3 irradiance = Irradiance(worldpos, N);
		color.xyz = irradiance;
	}
	
	FragColor = color;
}

\add_reflections.fs
#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_omr;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;


uniform samplerCube u_environment_texture1;
uniform samplerCube u_environment_texture2;
uniform samplerCube u_environment_texture3;
uniform samplerCube u_environment_texture4;
uniform vec3 u_probes_positions[4];

out vec4 FragColor;

void main()
{
	//extract uvs from pixel screenpos. From  [-1 1]to [0 1]
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	//From [0 1]to [-1 1], and inverse to get world position
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_pos = proj_worldpos.xyz / proj_worldpos.w;

	if(depth >= 1.0)
	{
		discard;
	}
	//revert the normalisation during pre-pass
	vec3 N = texture( u_normal_texture, uv ).xyz*2.0-vec3(1.0);
	N = normalize(N);
	
	float roughness = max(0.01, texture2D( u_omr, uv ).y); 
	float metalness = min(texture2D( u_omr, uv ).z,0.99);

	vec3 V = world_pos - u_camera_position;
	vec3 R = reflect(V,N);
	
	vec3 reflection = vec3(1.0,0.0,0.0);
	
	float aux_dist = 1000000.0;
	for(int i = 0; i < 4; i++){
		float dist = distance(world_pos, u_probes_positions[i]);
		if(dist < aux_dist){
			aux_dist = dist;
			if(i == 0)
				reflection = textureLod(u_environment_texture1, R, roughness*5.0).xyz;
			else if(i == 1)
				reflection = textureLod(u_environment_texture2, R, roughness*5.0).xyz;
			else if(i == 2)
				reflection = textureLod(u_environment_texture3, R, roughness*5.0).xyz;
			else if(i == 3)
				reflection = textureLod(u_environment_texture4, R, roughness*5.0).xyz;
		}
	}

	vec3 baseColor = texture( u_texture, uv ).xyz;
	reflection *= baseColor;
	FragColor = vec4( reflection, metalness);
}

\AAFX.fs
#version 330 core

uniform sampler2D u_texture;
uniform vec2 u_viewportSize;
uniform vec2 u_iViewportSize;
#define FXAA_REDUCE_MIN  (1.0/ 128.0)
#define FXAA_REDUCE_MUL  (1.0 / 8.0)
#define FXAA_SPAN_MAX    8.0

/* from mitsuhiko/webgl-meincraft based on the code on geeks3d.com */
/* fragCoord MUST BE IN PIXELS */

vec4 applyFXAA(sampler2D tex, vec2 fragCoord){
		vec4 color = vec4(0.0);
		/*vec2 u_iViewportSize = vec2(1.0 / u_viewportSize.x, 1.0 / u_viewportSize.y);*/
		vec3 rgbNW = texture2D(tex, (fragCoord + vec2(-1.0, -1.0)) * u_iViewportSize).xyz;
		vec3 rgbNE = texture2D(tex, (fragCoord + vec2(1.0, -1.0)) * u_iViewportSize).xyz;
		vec3 rgbSW = texture2D(tex, (fragCoord + vec2(-1.0, 1.0)) * u_iViewportSize).xyz;
		vec3 rgbSE = texture2D(tex, (fragCoord + vec2(1.0, 1.0)) * u_iViewportSize).xyz;
		vec3 rgbM  = texture2D(tex, fragCoord  * u_iViewportSize).xyz;
		vec3 luma = vec3(0.299, 0.587, 0.114);
		float lumaNW = dot(rgbNW, luma);
		float lumaNE = dot(rgbNE, luma);
		float lumaSW = dot(rgbSW, luma);
		float lumaSE = dot(rgbSE, luma);
		float lumaM  = dot(rgbM,  luma);
		float lumaMin = min(lumaM, min(min(lumaNW, lumaNE), min(lumaSW, lumaSE)));
		float lumaMax = max(lumaM, max(max(lumaNW, lumaNE), max(lumaSW, lumaSE)));
		vec2 dir;
		dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE));
		dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));
		float dirReduce = max((lumaNW + lumaNE + lumaSW + lumaSE) * (0.25 * FXAA_REDUCE_MUL), FXAA_REDUCE_MIN);
		float rcpDirMin = 1.0 / (min(abs(dir.x), abs(dir.y)) + dirReduce);
		dir = min(vec2(FXAA_SPAN_MAX, FXAA_SPAN_MAX), max(vec2(-FXAA_SPAN_MAX, -FXAA_SPAN_MAX), dir * rcpDirMin)) * u_iViewportSize;
		vec3 rgbA = 0.5 * (texture2D(tex, fragCoord * u_iViewportSize + dir * (1.0 / 3.0 - 0.5)).xyz + texture2D(tex, fragCoord * u_iViewportSize + dir * (2.0 / 3.0 - 0.5)).xyz);
		vec3 rgbB = rgbA * 0.5 + 0.25 * (texture2D(tex, fragCoord * u_iViewportSize + dir * -0.5).xyz + texture2D(tex, fragCoord * u_iViewportSize + dir * 0.5).xyz);
		//return vec4(rgbA,1.0);
		float lumaB = dot(rgbB, luma);
		if ((lumaB < lumaMin) || (lumaB > lumaMax))
			color = vec4(rgbA, 1.0);
		else
			color = vec4(rgbB, 1.0);
		return color;
}

out vec4 FragColor;
void main(){
	FragColor = applyFXAA(u_texture,gl_FragCoord.xy);
}

\volume_fog.fs
#version 330 core

in vec2 v_uv;

#include "light_uniforms"

uniform sampler2D u_depth_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform float u_near_plane;
uniform bool u_cast_shadow;
uniform float u_time;
uniform float u_air_density;
#define SAMPLES 64

out vec4 FragColor;

//jittering
vec3 random_offset(vec3 sample_position, vec3 step){
	float pos_offset = fract(sin(dot(gl_FragCoord.xy,vec2(12.9898,78.233)))*43758.5453);//pseudorandom
	return sample_position + step*pos_offset; //new sample position
}


void main()
{
	//extract uvs from pixel screenpos. From  [-1 1]to [0 1]
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	//From [0 1]to [-1 1], and inverse to get world position
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_pos = proj_worldpos.xyz / proj_worldpos.w;
	
	vec3 ray_direction = world_pos - u_camera_position;
	float dist = length(ray_direction);
	ray_direction = normalize(ray_direction);
	float step_factor = dist/float(SAMPLES);

	float air_density = u_air_density;

	vec3 ray_offset = ray_direction*step_factor;
	vec3 current_pos = random_offset(u_camera_position+ u_near_plane*ray_direction, ray_offset);

	vec4 final_color = vec4(0.0);
	vec3 light_color = gamma_to_linear(u_light_color);
	if(u_iteration == 1){
		light_color += gamma_to_linear(u_light_ambient);
	}
	for(int i = 0; i < SAMPLES; i++){
		float shadow_factor = 1.0;
		if(u_cast_shadow)
			shadow_factor = computeShadow(current_pos);

		vec3 L;
		float att_factor = 1.0;
		vec3 world_position = current_pos;
		float spotFactor = 1.0;
		#include "light_attenuation"

		vec4 sample_color = vec4(air_density)*vec4(light_color,1.0)*shadow_factor*att_factor*spotFactor*u_light_intensity;
		final_color += sample_color*length(ray_offset)*(1.0-final_color.w);

		if(final_color.w >= 0.99){ 
			break;
		}

		current_pos += ray_offset;
	}
	//final_color.xyz = linear_to_gamma(final_color.xyz);
	FragColor = final_color;
}

\gaussian_blur.fs
//code from: https://learnopengl.com/Advanced-Lighting/Bloom (bloom tutorial)
#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
  
uniform bool u_horizontal;
float u_weight[5] = float[] (0.227027, 0.1945946, 0.1216216, 0.054054, 0.016216);

out vec4 FragColor;
void main()
{             
    vec2 tex_offset = 1.0 / textureSize(u_texture, 0); // gets size of single texel
    vec3 result = texture(u_texture, v_uv).rgb * u_weight[0]; // current fragment's contribution
    if(u_horizontal)
    {
        for(int i = 1; i < 5; ++i)
        {
            result += texture(u_texture, v_uv + vec2(tex_offset.x * i, 0.0)).rgb * u_weight[i];
            result += texture(u_texture, v_uv - vec2(tex_offset.x * i, 0.0)).rgb * u_weight[i];
        }
    }
    else
    {
        for(int i = 1; i < 5; ++i)
        {
            result += texture(u_texture, v_uv + vec2(0.0, tex_offset.y * i)).rgb * u_weight[i];
            result += texture(u_texture, v_uv - vec2(0.0, tex_offset.y * i)).rgb * u_weight[i];
        }
    }
    FragColor = vec4(result, texture(u_texture, v_uv).w);
}

\bloom.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform sampler2D u_bright_texture;
uniform float u_bloom_intensity;

out vec4 FragColor;

void main()
{   
	vec3 blurred = texture(u_bright_texture,v_uv).xyz;
    vec3 color = texture(u_texture,v_uv).xyz;
	color += blurred*u_bloom_intensity;
    FragColor = vec4(color, 1.0);
}


\decal.fs

#version 330 core

in vec2 v_uv;


uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_albedo;
uniform sampler2D u_omr;

uniform sampler2D u_decal_albedo;
uniform sampler2D u_decal_omr;
//uniform sampler2D u_decal_normal; 

uniform bool u_has_albedo;
uniform bool u_has_omr;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;

uniform mat4 u_inv_model;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 OMR; //occlussion_metalness_roughness

void main()
{
	//extract uvs from pixel screenpos. From  [-1 1]to [0 1]
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	float depth = texture( u_depth_texture, uv ).x;
	if(depth >= 1)
		discard;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_pos = proj_worldpos.xyz / proj_worldpos.w;

	vec4 decal_color = texture( u_albedo, uv );
	vec4 normal = texture(u_normal_texture, uv);
	vec4 omr = texture(u_omr, uv);
	
	vec3 local_coord = (u_inv_model*vec4(world_pos,1.0)).xyz;
	vec2 decal_uv = (local_coord.xz/2.0)+vec2(0.5);
	if( decal_uv.x < 0.0 || decal_uv.x > 1.0 || decal_uv.y < 0.0 || decal_uv.y > 1.0)
		discard;


	if(u_has_albedo)
		decal_color = texture(u_decal_albedo, decal_uv);

	if(u_has_omr)
		omr = texture(u_decal_omr, decal_uv);

	/*if(u_has_normal){

	}*/

	if(decal_color.a < 0.5)
		discard;

	NormalColor = normal;
	OMR = omr;
	FragColor = decal_color;
}

\dof.fs
#version 330 core

in vec2 v_uv;


uniform sampler2D u_depth_texture;

uniform sampler2D u_in_focus;
uniform sampler2D u_out_focus;
uniform float u_min_distance;
uniform float u_max_distance;
uniform vec3 u_focus_point;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;

out vec4 FragColor;


void main()
{
	//extract uvs from pixel screenpos. From  [-1 1]to [0 1]
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	float depth = texture( u_depth_texture, uv ).x;
	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_pos = proj_worldpos.xyz / proj_worldpos.w;

	vec4 in_focus = texture(u_in_focus, uv);
	vec4 out_focus = texture(u_out_focus, uv);

	/*if(depth >= 1){
		FragColor = out_focus;
		return;
	}*/
	vec3 focus_point = u_camera_position + u_focus_point;
	float blur = smoothstep(u_min_distance, u_max_distance, abs(world_pos.x - focus_point.x));

	vec4 final_color = mix(in_focus, out_focus, blur);
	
		
	FragColor = final_color;
}